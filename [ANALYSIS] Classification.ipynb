{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "We have here document classification, using basic sklearn and pytorch, and named entity recognition using default settings from spacy and (optionally) Stanford NER. We use a variety of methods and find that:\n",
    "* Results are very stable between the ground truth and OCRed version of this dataset\n",
    "* Often, a classifier performs slightly better on the OCRed version of the dataset\n",
    "* These results are consistent over different text representations (e.g., count vertors, tf-idf, embeddings) and methods (Naive Bayes, SVM, Random Forests, MLP, deeper neural networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import jellyfish\n",
    "import numpy as np\n",
    "import os, codecs, re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# magics and warnings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "import os, random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "seed = 99\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "import nltk, gensim, sklearn, spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For this analysis we use the DBNL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_frames/full_df_DBNL_OCR.csv\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text_ground</th>\n",
       "      <th>genre</th>\n",
       "      <th>subgenre</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>edition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_vad003182501</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nBoekbeschouwing.\\nDe gemoedsgestel...</td>\n",
       "      <td>sec - letterkunde,non-fictie</td>\n",
       "      <td>tijdschrift / jaarboek</td>\n",
       "      <td>SEM1N\\t9\\n(\\tSIS)\\ns..\\n\f",
       "B OEKBESCHOUWI ' ,\\nv...</td>\n",
       "      <td>Vaderlandsche letteroefeningen. Jaargang 1825</td>\n",
       "      <td>1825</td>\n",
       "      <td>1ste druk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename                                        text_ground  \\\n",
       "0  _vad003182501  \\n\\n\\n\\n\\n\\nBoekbeschouwing.\\nDe gemoedsgestel...   \n",
       "\n",
       "                          genre                subgenre  \\\n",
       "0  sec - letterkunde,non-fictie  tijdschrift / jaarboek   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  SEM1N\\t9\\n(\\tSIS)\\ns..\\n\n",
       "B OEKBESCHOUWI ' ,\\nv...   \n",
       "\n",
       "                                           title  year    edition  \n",
       "0  Vaderlandsche letteroefeningen. Jaargang 1825  1825  1ste druk  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sec - letterkunde,non-fictie         77\n",
       "poëzie                               46\n",
       "non-fictie                           31\n",
       "sec - taalkunde                      25\n",
       "proza,sec - letterkunde              17\n",
       "proza                                 9\n",
       "proza,poëzie,non-fictie               5\n",
       "sec - letterkunde                     3\n",
       "poëzie,sec - letterkunde              2\n",
       "poëzie,jeugdliteratuur                2\n",
       "sec - letterkunde,jeugdliteratuur     1\n",
       "proza,drama                           1\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_classes(original_class):\n",
    "    \"Put together the main classes\"\n",
    "    \n",
    "    if original_class in [\"sec - letterkunde,non-fictie\",\"proza,sec - letterkunde\",\"proza\"]:\n",
    "        return \"sec - letterkunde\"\n",
    "    elif \"poëzie\" in original_class:\n",
    "        return \"poëzie\"\n",
    "    elif original_class == \"sec - taalkunde\":\n",
    "        return \"sec - taalkunde\"\n",
    "    elif original_class == \"non-fictie\":\n",
    "        return \"non-fictie\"\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.7 ms, sys: 295 µs, total: 3 ms\n",
      "Wall time: 3.05 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "869"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# test the speed of the levenshtein distance\n",
    "\n",
    "jellyfish.levenshtein_distance(df[\"text_ground\"].values[0][:1000],df[\"text_ocr\"].values[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"consolidated_genre\"] = df[\"genre\"].apply(consolidate_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text_ground</th>\n",
       "      <th>genre</th>\n",
       "      <th>subgenre</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>edition</th>\n",
       "      <th>consolidated_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_vad003182501</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nBoekbeschouwing.\\nDe gemoedsgestel...</td>\n",
       "      <td>sec - letterkunde,non-fictie</td>\n",
       "      <td>tijdschrift / jaarboek</td>\n",
       "      <td>SEM1N\\t9\\n(\\tSIS)\\ns..\\n\f",
       "B OEKBESCHOUWI ' ,\\nv...</td>\n",
       "      <td>Vaderlandsche letteroefeningen. Jaargang 1825</td>\n",
       "      <td>1825</td>\n",
       "      <td>1ste druk</td>\n",
       "      <td>sec - letterkunde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename                                        text_ground  \\\n",
       "0  _vad003182501  \\n\\n\\n\\n\\n\\nBoekbeschouwing.\\nDe gemoedsgestel...   \n",
       "\n",
       "                          genre                subgenre  \\\n",
       "0  sec - letterkunde,non-fictie  tijdschrift / jaarboek   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  SEM1N\\t9\\n(\\tSIS)\\ns..\\n\n",
       "B OEKBESCHOUWI ' ,\\nv...   \n",
       "\n",
       "                                           title  year    edition  \\\n",
       "0  Vaderlandsche letteroefeningen. Jaargang 1825  1825  1ste druk   \n",
       "\n",
       "  consolidated_genre  \n",
       "0  sec - letterkunde  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['consolidated_genre'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 9)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nl_core_news_sm==2.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/nl_core_news_sm-2.0.0/nl_core_news_sm-2.0.0.tar.gz (36.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 36.7 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25h\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /anaconda3/envs/ocr_lm/lib/python3.7/site-packages/nl_core_news_sm -->\n",
      "    /anaconda3/envs/ocr_lm/lib/python3.7/site-packages/spacy/data/nl\n",
      "\n",
      "    You can now load the model via spacy.load('nl')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ground = df[\"text_ground\"].values\n",
    "sample_ocr = df[\"text_ocr\"].values\n",
    "labels = df[\"consolidated_genre\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "print(len(sample_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot([len(x.split()) for x in sample_ground], label=\"Ground\", kde=False, color=\"green\", bins=30)\n",
    "sns.distplot([len(x.split()) for x in sample_ocr], label=\"OCR\", kde=False, color=\"red\", bins=30)\n",
    "plt.title(\"Document length\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the number of characters in use for each document\n",
    "\n",
    "LIMIT = 100000\n",
    "\n",
    "sample_ground = [x[:LIMIT] for x in sample_ground]\n",
    "sample_ocr = [x[:LIMIT] for x in sample_ocr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot([len(x) for x in sample_ground], label=\"Ground\", kde=False, color=\"green\", bins=30)\n",
    "sns.distplot([len(x) for x in sample_ocr], label=\"OCR\", kde=False, color=\"red\", bins=30)\n",
    "plt.title(\"Document length\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing\n",
    "We apply a canonical pre-processing pipeline, including the following steps:\n",
    "\n",
    "* Remove stop-words\n",
    "* Lemmatize\n",
    "* Lowercase\n",
    "* Remove tokens shorter than 3 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('nl')\n",
    "STOPWORDS = spacy.lang.nl.stop_words.STOP_WORDS\n",
    "STOPWORDS.add(\"eene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 39s, sys: 4min 55s, total: 22min 35s\n",
      "Wall time: 15min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_docs = list()\n",
    "for doc in nlp.pipe(sample_ocr, n_threads=5, batch_size=10):\n",
    "\n",
    "    # Process document using Spacy NLP pipeline.\n",
    "    #ents = doc.ents  # Named entities\n",
    "\n",
    "    # Keep only words (no numbers, no punctuation).\n",
    "    # Lemmatize tokens, remove punctuation and remove stopwords.\n",
    "    doc = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "    # Remove common words from a stopword list and keep only words of length 3 or more.\n",
    "    doc = [token.lower() for token in doc if token not in STOPWORDS and len(token) > 2]\n",
    "\n",
    "    # Add named entities, but only if they are a compound of more than one word.\n",
    "    #doc.extend([str(entity) for entity in ents if len(entity) > 1])\n",
    "\n",
    "    processed_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = processed_docs\n",
    "del processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need to run the same pipeline twice, for ground truth and OCR documents. Comment/uncomment this part each time:\n",
    "#docs_ground = docs\n",
    "docs_ocr = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save corpora\n",
    "import pickle\n",
    "\n",
    "with open('folder_classification/docs_ground.pkl', 'wb') as handle:\n",
    "    pickle.dump(docs_ground, handle)\n",
    "with open('folder_classification/docs_ocr.pkl', 'wb') as handle:\n",
    "    pickle.dump(docs_ocr, handle)\n",
    "with open('folder_classification/labels.pkl', 'wb') as handle:\n",
    "    pickle.dump(labels, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start from the pre-processed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpora\n",
    "import pickle\n",
    "\n",
    "docs_ground = list()\n",
    "docs_ocr = list()\n",
    "labels = list()\n",
    "\n",
    "with open('folder_classification/docs_ground.pkl', 'rb') as handle:\n",
    "    docs_ground = pickle.load(handle)\n",
    "with open('folder_classification/docs_ocr.pkl', 'rb') as handle:\n",
    "    docs_ocr = pickle.load(handle)\n",
    "with open('folder_classification/labels.pkl', 'rb') as handle:\n",
    "    labels = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boekbeschouwing',\n",
       " 'gemoedsgesteldheid',\n",
       " 'david',\n",
       " 'onder',\n",
       " 'zijne',\n",
       " 'verschillende',\n",
       " 'lotgevallen',\n",
       " 'zijne',\n",
       " 'psalmen',\n",
       " 'opgemaakt']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ground[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sis',\n",
       " 'oekbeschouwi',\n",
       " 'voor',\n",
       " 'erland',\n",
       " 'scfie',\n",
       " 'letteroefeningen',\n",
       " 'tij',\n",
       " 'schr',\n",
       " 'van',\n",
       " 'kunsten']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ocr[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple classifiers with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sec - letterkunde': 103,\n",
       "         'sec - taalkunde': 25,\n",
       "         'non-fictie': 31,\n",
       "         'poëzie': 55})"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# these are the labels\n",
    "c = Counter(labels)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_g, test_g, labels_train_g, labels_test_g = train_test_split(docs_ground, labels, test_size=0.2, random_state=seed)\n",
    "train_o, test_o, labels_train_o, labels_test_o = train_test_split(docs_ocr, labels, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv (used later on for PyTorch)\n",
    "\n",
    "with open('folder_classification/train_g.csv', 'w') as handle:\n",
    "    for t,l in zip(train_g,labels_train_g):\n",
    "        handle.write(\"\\\"\"+\" \".join(t)+\"\\\",\"+l+\"\\n\")\n",
    "with open('folder_classification/train_o.csv', 'w') as handle:\n",
    "    for t,l in zip(train_o,labels_train_o):\n",
    "        handle.write(\"\\\"\"+\" \".join(t)+\"\\\",\"+l+\"\\n\")\n",
    "with open('folder_classification/test_g.csv', 'w') as handle:\n",
    "    for t,l in zip(test_g,labels_test_g):\n",
    "        handle.write(\"\\\"\"+\" \".join(t)+\"\\\",\"+l+\"\\n\")\n",
    "with open('folder_classification/test_o.csv', 'w') as handle:\n",
    "    for t,l in zip(test_o,labels_test_o):\n",
    "        handle.write(\"\\\"\"+\" \".join(t)+\"\\\",\"+l+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 58477)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature extractors\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# remove terms only in one doc and turn off prepocessing (which we did already)\n",
    "count_vect_g = CountVectorizer(min_df=2, analyzer=lambda x: x)\n",
    "tfidf_vect_g = TfidfVectorizer(min_df=2, analyzer=lambda x: x) \n",
    "count_vect_o = CountVectorizer(min_df=2, analyzer=lambda x: x) \n",
    "tfidf_vect_o = TfidfVectorizer(min_df=2, analyzer=lambda x: x) \n",
    "\n",
    "count_tr_g = count_vect_g.fit(train_g)\n",
    "count_tr_o = count_vect_o.fit(train_o)\n",
    "tfidf_tr_g = tfidf_vect_g.fit(train_g)\n",
    "tfidf_tr_o = tfidf_vect_o.fit(train_o)\n",
    "\n",
    "X_train_g_counts = count_tr_g.transform(train_g)\n",
    "X_train_g_counts.shape\n",
    "X_train_o_counts = count_tr_o.transform(train_o)\n",
    "X_train_o_counts.shape\n",
    "\n",
    "X_train_g_tfidf = tfidf_tr_g.transform(train_g)\n",
    "X_train_o_tfidf = tfidf_tr_o.transform(train_o)\n",
    "X_train_o_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 54907)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_g_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classifiers: NB, SVC, RF, MLP\n",
    "\n",
    "#### Count-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_g_NB = MultinomialNB().fit(X_train_g_counts, labels_train_g)\n",
    "clf_o_NB = MultinomialNB().fit(X_train_o_counts, labels_train_o)\n",
    "classifiers.append((\"NB\",clf_g_NB,clf_o_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_g_SVM = svm.SVC(decision_function_shape='ovr').fit(X_train_g_counts, labels_train_g)\n",
    "clf_o_SVM = svm.SVC(decision_function_shape='ovr').fit(X_train_o_counts, labels_train_o)\n",
    "classifiers.append((\"SVM\",clf_g_SVM,clf_o_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_g_RF = RandomForestClassifier(max_depth=10, n_estimators=20, max_features=100).fit(X_train_g_counts, labels_train_g)\n",
    "clf_o_RF = RandomForestClassifier(max_depth=10, n_estimators=20, max_features=100).fit(X_train_o_counts, labels_train_o)\n",
    "classifiers.append((\"RF\",clf_g_RF,clf_o_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_g_MLP = MLPClassifier(hidden_layer_sizes=(100, 50, 25)).fit(X_train_g_counts, labels_train_g)\n",
    "clf_o_MLP = MLPClassifier(hidden_layer_sizes=(100, 50, 25)).fit(X_train_o_counts, labels_train_o)\n",
    "classifiers.append((\"MLP\",clf_g_MLP,clf_o_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth\n",
      "------\n",
      "\n",
      "NB\n",
      "0.8604651162790697\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.85      0.73      0.79        15\n",
      "sec - letterkunde       0.81      1.00      0.89        17\n",
      "  sec - taalkunde       1.00      0.75      0.86         4\n",
      "\n",
      "         accuracy                           0.86        43\n",
      "        macro avg       0.91      0.84      0.87        43\n",
      "     weighted avg       0.87      0.86      0.86        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 11  4  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  0  3]]\n",
      "\n",
      "------\n",
      "\n",
      "SVM\n",
      "0.813953488372093\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.82      0.60      0.69        15\n",
      "sec - letterkunde       0.74      1.00      0.85        17\n",
      "  sec - taalkunde       1.00      0.75      0.86         4\n",
      "\n",
      "         accuracy                           0.81        43\n",
      "        macro avg       0.89      0.80      0.83        43\n",
      "     weighted avg       0.83      0.81      0.81        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0  9  6  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  0  3]]\n",
      "\n",
      "------\n",
      "\n",
      "RF\n",
      "0.7441860465116279\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.82      0.60      0.69        15\n",
      "sec - letterkunde       0.68      1.00      0.81        17\n",
      "  sec - taalkunde       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.74        43\n",
      "        macro avg       0.62      0.61      0.61        43\n",
      "     weighted avg       0.72      0.74      0.71        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0  9  5  1]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  3  0]]\n",
      "\n",
      "------\n",
      "\n",
      "MLP\n",
      "0.8604651162790697\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.85      0.73      0.79        15\n",
      "sec - letterkunde       0.81      1.00      0.89        17\n",
      "  sec - taalkunde       1.00      0.75      0.86         4\n",
      "\n",
      "         accuracy                           0.86        43\n",
      "        macro avg       0.91      0.84      0.87        43\n",
      "     weighted avg       0.87      0.86      0.86        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 11  4  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  0  3]]\n",
      "\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "X_test_g_counts = count_tr_g.transform(test_g)\n",
    "\n",
    "print(\"Ground truth\\n------\\n\")\n",
    "for cl in classifiers:\n",
    "    print(cl[0])\n",
    "    predicted = cl[1].predict(X_test_g_counts)\n",
    "    print(np.mean(predicted == labels_test_g))\n",
    "    print(metrics.classification_report(labels_test_g, predicted))\n",
    "    print(metrics.confusion_matrix(labels_test_g, predicted))\n",
    "    print(\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR\n",
      "------\n",
      "\n",
      "NB\n",
      "0.8837209302325582\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.86      0.80      0.83        15\n",
      "sec - letterkunde       0.85      1.00      0.92        17\n",
      "  sec - taalkunde       1.00      0.75      0.86         4\n",
      "\n",
      "         accuracy                           0.88        43\n",
      "        macro avg       0.93      0.85      0.88        43\n",
      "     weighted avg       0.89      0.88      0.88        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 12  3  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  0  3]]\n",
      "\n",
      "------\n",
      "\n",
      "SVM\n",
      "0.8604651162790697\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.85      0.73      0.79        15\n",
      "sec - letterkunde       0.81      1.00      0.89        17\n",
      "  sec - taalkunde       1.00      0.75      0.86         4\n",
      "\n",
      "         accuracy                           0.86        43\n",
      "        macro avg       0.91      0.84      0.87        43\n",
      "     weighted avg       0.87      0.86      0.86        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 11  4  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  0  3]]\n",
      "\n",
      "------\n",
      "\n",
      "RF\n",
      "0.813953488372093\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.85      0.73      0.79        15\n",
      "sec - letterkunde       0.77      1.00      0.87        17\n",
      "  sec - taalkunde       0.50      0.25      0.33         4\n",
      "\n",
      "         accuracy                           0.81        43\n",
      "        macro avg       0.78      0.71      0.73        43\n",
      "     weighted avg       0.81      0.81      0.80        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 11  3  1]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  2  1]]\n",
      "\n",
      "------\n",
      "\n",
      "MLP\n",
      "0.8604651162790697\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.85      0.73      0.79        15\n",
      "sec - letterkunde       0.85      1.00      0.92        17\n",
      "  sec - taalkunde       0.75      0.75      0.75         4\n",
      "\n",
      "         accuracy                           0.86        43\n",
      "        macro avg       0.86      0.84      0.84        43\n",
      "     weighted avg       0.86      0.86      0.86        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 11  3  1]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  0  3]]\n",
      "\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_o_counts = count_tr_o.transform(test_o)\n",
    "\n",
    "print(\"OCR\\n------\\n\")\n",
    "for cl in classifiers:\n",
    "    print(cl[0])\n",
    "    predicted = cl[2].predict(X_test_o_counts)\n",
    "    print(np.mean(predicted == labels_test_o))\n",
    "    print(metrics.classification_report(labels_test_o, predicted))\n",
    "    print(metrics.confusion_matrix(labels_test_o, predicted))\n",
    "    print(\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-Idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_g_NB = MultinomialNB().fit(X_train_g_tfidf, labels_train_g)\n",
    "clf_o_NB = MultinomialNB().fit(X_train_o_tfidf, labels_train_o)\n",
    "classifiers.append((\"NB\",clf_g_NB,clf_o_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_g_SVM = svm.SVC(gamma=2, C=1, decision_function_shape='ovr').fit(X_train_g_tfidf, labels_train_g)\n",
    "clf_o_SVM = svm.SVC(gamma=2, C=1, decision_function_shape='ovr').fit(X_train_o_tfidf, labels_train_o)\n",
    "classifiers.append((\"SVM\",clf_g_SVM,clf_o_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_g_RF = RandomForestClassifier(max_depth=10, n_estimators=20, max_features=100).fit(X_train_g_tfidf, labels_train_g)\n",
    "clf_o_RF = RandomForestClassifier(max_depth=10, n_estimators=20, max_features=100).fit(X_train_o_tfidf, labels_train_o)\n",
    "classifiers.append((\"RF\",clf_g_RF,clf_o_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_g_MLP = MLPClassifier(hidden_layer_sizes=(100, 50, 25)).fit(X_train_g_tfidf, labels_train_g)\n",
    "clf_o_MLP = MLPClassifier(hidden_layer_sizes=(100, 50, 25)).fit(X_train_o_tfidf, labels_train_o)\n",
    "classifiers.append((\"MLP\",clf_g_MLP,clf_o_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth\n",
      "------\n",
      "\n",
      "NB\n",
      "0.4186046511627907\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       0.00      0.00      0.00         7\n",
      "           poëzie       1.00      0.07      0.12        15\n",
      "sec - letterkunde       0.40      1.00      0.58        17\n",
      "  sec - taalkunde       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.42        43\n",
      "        macro avg       0.35      0.27      0.18        43\n",
      "     weighted avg       0.51      0.42      0.27        43\n",
      "\n",
      "[[ 0  0  7  0]\n",
      " [ 0  1 14  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  0  4  0]]\n",
      "\n",
      "------\n",
      "\n",
      "SVM\n",
      "0.7906976744186046\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.82      0.60      0.69        15\n",
      "sec - letterkunde       0.71      1.00      0.83        17\n",
      "  sec - taalkunde       1.00      0.50      0.67         4\n",
      "\n",
      "         accuracy                           0.79        43\n",
      "        macro avg       0.88      0.74      0.78        43\n",
      "     weighted avg       0.82      0.79      0.78        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0  9  6  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  1  2]]\n",
      "\n",
      "------\n",
      "\n",
      "RF\n",
      "0.813953488372093\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.79      0.73      0.76        15\n",
      "sec - letterkunde       0.76      0.94      0.84        17\n",
      "  sec - taalkunde       1.00      0.50      0.67         4\n",
      "\n",
      "         accuracy                           0.81        43\n",
      "        macro avg       0.89      0.76      0.80        43\n",
      "     weighted avg       0.83      0.81      0.81        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 11  4  0]\n",
      " [ 0  1 16  0]\n",
      " [ 0  1  1  2]]\n",
      "\n",
      "------\n",
      "\n",
      "MLP\n",
      "0.8837209302325582\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       0.86      0.86      0.86         7\n",
      "           poëzie       0.86      0.80      0.83        15\n",
      "sec - letterkunde       0.89      1.00      0.94        17\n",
      "  sec - taalkunde       1.00      0.75      0.86         4\n",
      "\n",
      "         accuracy                           0.88        43\n",
      "        macro avg       0.90      0.85      0.87        43\n",
      "     weighted avg       0.89      0.88      0.88        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 1 12  2  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  0  3]]\n",
      "\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "X_test_g_tfidf = tfidf_tr_g.transform(test_g)\n",
    "\n",
    "print(\"Ground truth\\n------\\n\")\n",
    "for cl in classifiers:\n",
    "    print(cl[0])\n",
    "    predicted = cl[1].predict(X_test_g_tfidf)\n",
    "    print(np.mean(predicted == labels_test_g))\n",
    "    print(metrics.classification_report(labels_test_g, predicted))\n",
    "    print(metrics.confusion_matrix(labels_test_g, predicted))\n",
    "    print(\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth\n",
      "------\n",
      "\n",
      "NB\n",
      "0.4186046511627907\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       0.00      0.00      0.00         7\n",
      "           poëzie       1.00      0.07      0.12        15\n",
      "sec - letterkunde       0.40      1.00      0.58        17\n",
      "  sec - taalkunde       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.42        43\n",
      "        macro avg       0.35      0.27      0.18        43\n",
      "     weighted avg       0.51      0.42      0.27        43\n",
      "\n",
      "[[ 0  0  7  0]\n",
      " [ 0  1 14  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  0  4  0]]\n",
      "\n",
      "------\n",
      "\n",
      "SVM\n",
      "0.7674418604651163\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.83      0.67      0.74        15\n",
      "sec - letterkunde       0.68      1.00      0.81        17\n",
      "  sec - taalkunde       0.00      0.00      0.00         4\n",
      "\n",
      "         accuracy                           0.77        43\n",
      "        macro avg       0.63      0.63      0.62        43\n",
      "     weighted avg       0.72      0.77      0.73        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 10  5  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  3  0]]\n",
      "\n",
      "------\n",
      "\n",
      "RF\n",
      "0.7674418604651163\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.77      0.67      0.71        15\n",
      "sec - letterkunde       0.70      0.94      0.80        17\n",
      "  sec - taalkunde       1.00      0.25      0.40         4\n",
      "\n",
      "         accuracy                           0.77        43\n",
      "        macro avg       0.87      0.68      0.71        43\n",
      "     weighted avg       0.80      0.77      0.75        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 10  5  0]\n",
      " [ 0  1 16  0]\n",
      " [ 0  1  2  1]]\n",
      "\n",
      "------\n",
      "\n",
      "MLP\n",
      "0.8837209302325582\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       non-fictie       1.00      0.86      0.92         7\n",
      "           poëzie       0.86      0.80      0.83        15\n",
      "sec - letterkunde       0.85      1.00      0.92        17\n",
      "  sec - taalkunde       1.00      0.75      0.86         4\n",
      "\n",
      "         accuracy                           0.88        43\n",
      "        macro avg       0.93      0.85      0.88        43\n",
      "     weighted avg       0.89      0.88      0.88        43\n",
      "\n",
      "[[ 6  1  0  0]\n",
      " [ 0 12  3  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  1  0  3]]\n",
      "\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_o_tfidf = tfidf_tr_o.transform(test_o)\n",
    "\n",
    "print(\"OCR\\n------\\n\")\n",
    "for cl in classifiers:\n",
    "    print(cl[0])\n",
    "    predicted = cl[2].predict(X_test_o_tfidf)\n",
    "    print(np.mean(predicted == labels_test_o))\n",
    "    print(metrics.classification_report(labels_test_o, predicted))\n",
    "    print(metrics.confusion_matrix(labels_test_o, predicted))\n",
    "    print(\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "We here use a more advanced classifier based on neural networks, using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "from torchtext.data import Field, LabelField\n",
    "\n",
    "tokenize = lambda x: x.split()\n",
    "TEXT_g = Field(sequential=True, tokenize=tokenize, lower=False)\n",
    "LABEL_g = LabelField(sequential=False)\n",
    "datafields_g = [(\"text\", TEXT_g), (\"label\", LABEL_g)]\n",
    "\n",
    "TEXT_o = Field(sequential=True, tokenize=tokenize, lower=False)\n",
    "LABEL_o = LabelField(sequential=False)\n",
    "datafields_o = [(\"text\", TEXT_o), (\"label\", LABEL_o)]\n",
    "\n",
    "torch_train_g, torch_test_g = data.TabularDataset.splits(\n",
    "               path=\"folder_classification\", # the root directory where the data lies\n",
    "               train='train_g.csv', validation=\"test_g.csv\",\n",
    "               format='csv',\n",
    "               skip_header=False,\n",
    "               fields=datafields_g)\n",
    "torch_train_o, torch_test_o = data.TabularDataset.splits(\n",
    "               path=\"folder_classification\", # the root directory where the data lies\n",
    "               train='train_o.csv', validation=\"test_o.csv\",\n",
    "               format='csv',\n",
    "               skip_header=False,\n",
    "               fields=datafields_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabs\n",
    "TEXT_g.build_vocab(torch_train_g)\n",
    "TEXT_o.build_vocab(torch_train_o)\n",
    "LABEL_g.build_vocab(torch_train_g)\n",
    "LABEL_o.build_vocab(torch_train_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sec - letterkunde': 86,\n",
       "         'poëzie': 40,\n",
       "         'non-fictie': 24,\n",
       "         'sec - taalkunde': 21})"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_g.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'sec - letterkunde': 0,\n",
       "             'poëzie': 1,\n",
       "             'non-fictie': 2,\n",
       "             'sec - taalkunde': 3})"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_g.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'label'])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_train_g[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sec - letterkunde'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_train_g[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boekbeschouwing',\n",
       " 'voorlezingen',\n",
       " 'geschiedenis',\n",
       " 'opvoeding',\n",
       " 'des',\n",
       " 'menschdoms',\n",
       " 'god',\n",
       " 'komst',\n",
       " 'jezus',\n",
       " 'christus']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_train_g[0].text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "# This one is largely taken from: https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextClass(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False) # embedding bag + linear layer method. With sparese=True we need to use SparseAdam below\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text.permute(1, 0))\n",
    "        preds = self.fc(embedded)\n",
    "        #preds = F.log_softmax(preds, dim=-1) #NB to be removed for some losses!\n",
    "        return preds\n",
    "\n",
    "# from: https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "class SimpleLSTMBaseline(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, emb_dim, num_class, num_linear=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=1)\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, seq):\n",
    "        hdn, _ = self.encoder(self.embedding(seq))\n",
    "        feature = hdn[-1, :, :]\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "        preds = self.fc(feature)\n",
    "        #preds = F.log_softmax(preds, dim=-1) #NB to be removed for some losses!\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 15\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test\n",
    "\n",
    "Choose here which version of the dataset to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHICH_DATASET = \"ground\" # \"ocr\" \"ground\"\n",
    "VOCAB_SIZE = len(TEXT_g.vocab)\n",
    "if WHICH_DATASET == \"ocr\":\n",
    "    VOCAB_SIZE = len(TEXT_o.vocab)\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASS = len(c)\n",
    "model = TextClass(VOCAB_SIZE, EMBED_DIM, NUM_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sec - letterkunde': 103,\n",
       "         'sec - taalkunde': 25,\n",
       "         'non-fictie': 31,\n",
       "         'poëzie': 55})"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterators\n",
    "# largely from: https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "train_g_iter, test_g_iter = BucketIterator.splits(\n",
    "    (torch_train_g, torch_test_g), # we pass in the datasets we want the iterator to draw data from\n",
    "    batch_sizes=(BATCH_SIZE, BATCH_SIZE),\n",
    "    device=device, # if you want to use the GPU, specify the GPU number here\n",
    "    sort_key=lambda x: len(x.text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "    sort_within_batch=False,\n",
    "    repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")\n",
    "train_o_iter, test_o_iter = BucketIterator.splits(\n",
    "    (torch_train_o, torch_test_o), # we pass in the datasets we want the iterator to draw data from\n",
    "    batch_sizes=(BATCH_SIZE, BATCH_SIZE),\n",
    "    device=device, # if you want to use the GPU, specify the GPU number here\n",
    "    sort_key=lambda x: len(x.text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "    sort_within_batch=False,\n",
    "    repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test = next(iter(train_g_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4502,    229,   9844,  ...,    125,    127,   5385],\n",
       "        [   554,    582,  10197,  ...,    229,   1040,     25],\n",
       "        [ 26358,   1048,   2275,  ...,    582,    260,    514],\n",
       "        ...,\n",
       "        [     1,      1,      1,  ...,      1,      1,    928],\n",
       "        [     1,      1,      1,  ...,      1,      1,   9045],\n",
       "        [     1,      1,      1,  ...,      1,      1, 115133]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 2, 2, 2, 0, 1, 1, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_var):\n",
    "        self.dl, self.x_var, self.y_var = dl, x_var, y_var # we pass in the list of attributes for x \n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            y = getattr(batch, self.y_var)\n",
    "            \n",
    "            \"\"\"\n",
    "            if self.y_vars is not None: # we will concatenate y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "            \"\"\"\n",
    "            \n",
    "            yield (x, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LEN = len(torch_train_g)\n",
    "TEST_LEN = len(torch_test_g)\n",
    "train_dl = BatchWrapper(train_g_iter, \"text\", \"label\")\n",
    "test_dl = BatchWrapper(test_g_iter, \"text\", \"label\")\n",
    "if WHICH_DATASET == \"ocr\":\n",
    "    TRAIN_LEN = len(torch_train_o)\n",
    "    TEST_LEN = len(torch_test_o)\n",
    "    train_dl = BatchWrapper(train_o_iter, \"text\", \"label\")\n",
    "    test_dl = BatchWrapper(test_o_iter, \"text\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c592c7d8abb4631b02ef19817b9e7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.0783, Validation Loss: 0.0693; Train acc: 0.5029, Validation acc: 0.4419.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6241db5b584933878593c1f072a9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.0452, Validation Loss: 0.0475; Train acc: 0.7485, Validation acc: 0.7674.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c603d1e6c97b46d7b37dc96618dda6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.0252, Validation Loss: 0.0363; Train acc: 0.9240, Validation acc: 0.7907.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350086da95014ba5a4f95a97607c7cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.0143, Validation Loss: 0.0326; Train acc: 0.9591, Validation acc: 0.8372.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25aeaf88ca745b488b3ff87522824da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.0086, Validation Loss: 0.0300; Train acc: 0.9883, Validation acc: 0.8605.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc8c841b2554944b9a7516ac38c49e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 0.0046, Validation Loss: 0.0311; Train acc: 0.9942, Validation acc: 0.8605.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a099b5f43044ac0afb5833b41eb6121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 0.0029, Validation Loss: 0.0298; Train acc: 1.0000, Validation acc: 0.8605.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275926978a0141e2a909b43cc9756ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 0.0018, Validation Loss: 0.0303; Train acc: 1.0000, Validation acc: 0.8605.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5de1d8443a471885de65f2830e9af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: 0.0014, Validation Loss: 0.0299; Train acc: 1.0000, Validation acc: 0.8605.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81499ac4975441da8f11a24e6a572d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 0.0011, Validation Loss: 0.0294; Train acc: 1.0000, Validation acc: 0.8605.\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "#loss_func = nn.BCEWithLogitsLoss()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "#loss_func = nn.NLLLoss()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    running_batch = 1\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in tqdm.tqdm_notebook(train_dl): # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "        #print(x.shape)\n",
    "\n",
    "        preds = model(x)\n",
    "        #print(preds.shape)\n",
    "        #print(y.view(-1,1).shape)\n",
    "        #print(y.view(-1,1).dtype)\n",
    "        #print(y.view(-1,1))\n",
    "        #print(preds)\n",
    "        loss = loss_func(preds,y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_acc += (preds.argmax(1) == y).sum().item()\n",
    "        #print('Batch Training loss: {:.4f}, Train acc: {:.4f}.'.format(loss.item(), train_acc / (BATCH_SIZE*running_batch)))\n",
    "        #running_loss += loss.data * x.size(0)\n",
    "        \n",
    "        running_batch += 1\n",
    "\n",
    "    epoch_loss = running_loss / TRAIN_LEN\n",
    "\n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in test_dl:\n",
    "        preds = model(x)\n",
    "        #print(preds)\n",
    "        #print(y)\n",
    "        loss = loss_func(preds,y)\n",
    "        val_loss += loss.item()\n",
    "        val_acc += (preds.argmax(1) == y).sum().item()\n",
    "\n",
    "    val_loss /= TEST_LEN\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}; Train acc: {:.4f}, Validation acc: {:.4f}.'.format(epoch, epoch_loss, val_loss, train_acc/TRAIN_LEN, val_acc/TEST_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR:\n",
    "# Epoch: 10, Training Loss: 0.0009, Validation Loss: 0.0251; Train acc: 1.0000, Validation acc: 0.9302.\n",
    "\n",
    "# Ground:\n",
    "# Epoch: 10, Training Loss: 0.0011, Validation Loss: 0.0294; Train acc: 1.0000, Validation acc: 0.8605."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "Work in progress on assessinng the overlap of a NER pipeline on the two versions of the dataset is here for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('nl')\n",
    "STOPWORDS = spacy.lang.nl.stop_words.STOP_WORDS\n",
    "STOPWORDS.add(\"eene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 18s, sys: 8min 7s, total: 39min 26s\n",
      "Wall time: 25min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_ents_g = list()\n",
    "for doc in nlp.pipe(sample_ground, n_threads=5, batch_size=10):\n",
    "    processed_ents_g.append(doc.ents)\n",
    "processed_ents_o = list()\n",
    "for doc in nlp.pipe(sample_ocr, n_threads=5, batch_size=10):\n",
    "    processed_ents_o.append(doc.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess Jaccard coeff overlap\n",
    "* MACRO\n",
    "consider all ents together\n",
    "* MICRO\n",
    "consider all documents separately and then average\n",
    "* Surface and/or entity type\n",
    "* Consider repetitions or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a,b):\n",
    "    return len(set(a).intersection(set(b)))/len(set(a).union(set(b)))\n",
    "def left_jaccard(a,b):\n",
    "    return len(set(a).intersection(set(b)))/len(set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_surfs_surface_g = [[e.text.strip() for e in doc] for doc in processed_ents_g]\n",
    "all_surfs_surface_o = [[e.text.strip() for e in doc] for doc in processed_ents_o]\n",
    "all_ents_surface_g = [[e.text.strip() +\"-\"+ e.label_ for e in doc] for doc in processed_ents_g]\n",
    "all_ents_surface_o = [[e.text.strip() +\"-\"+ e.label_ for e in doc] for doc in processed_ents_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SEM1N\\t9\\n(\\tSIS)\\ns..\\n\\x0cB OEKBESCHOUWI ' ,\\nvOOR\\n1 8 US.\\n\\x0c\\n\\x0cV AD ERLAND SCFIE\\nLETTEROEFENINGEN , \\nor\\nTIJ D SCHR IF T\\nVAN\\nKUNSTEN EN WETENSCHAPPFN,\\nWAARIN DR\\nBOEKEN EN SCHRIFTEN,\\nDIE DAGELIJKS IN ONS VADERL\""
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ocr[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEM1N\\t9-LOC',\n",
       " 'SIS-LOC',\n",
       " 's..\\n\\x0cB-ORG',\n",
       " 'vOOR-ORG',\n",
       " 'US-LOC',\n",
       " 'AD ERLAND-MISC',\n",
       " 'SCFIE-ORG',\n",
       " 'LETTEROEFENINGEN-ORG',\n",
       " 'or-ORG',\n",
       " 'TIJ D-MISC']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ents_surface_o[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEM1N\\t9',\n",
       " 'SIS',\n",
       " 's..\\n\\x0cB',\n",
       " 'vOOR',\n",
       " 'US',\n",
       " 'AD ERLAND',\n",
       " 'SCFIE',\n",
       " 'LETTEROEFENINGEN',\n",
       " 'or',\n",
       " 'TIJ D']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_surfs_surface_o[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per document and overall\n",
    "jaccard_surf_doc = list()\n",
    "jaccard_ent_doc = list()\n",
    "for doc_g,doc_o in zip(all_surfs_surface_g,all_surfs_surface_o):\n",
    "    jac = jaccard(doc_g,doc_o)\n",
    "    jaccard_surf_doc.append(jac)\n",
    "for doc_g,doc_o in zip(all_ents_surface_g,all_ents_surface_o):\n",
    "    jac = jaccard(doc_g,doc_o)\n",
    "    jaccard_ent_doc.append(jac)\n",
    "    \n",
    "jaccard_surf = jaccard([e for doc_g in all_surfs_surface_g for e in doc_g],[e for doc_o in all_surfs_surface_o for e in doc_o])\n",
    "jaccard_ent = jaccard([e for doc_g in all_ents_surface_g for e in doc_g],[e for doc_o in all_ents_surface_o for e in doc_o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2332332873219926"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_surf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20393713784326162"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2912726467613969"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(jaccard_surf_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2364678732298048"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(jaccard_ent_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per document and overall\n",
    "jaccard_surf_doc = list()\n",
    "jaccard_ent_doc = list()\n",
    "for doc_g,doc_o in zip(all_surfs_surface_g,all_surfs_surface_o):\n",
    "    jac = left_jaccard(doc_g,doc_o)\n",
    "    jaccard_surf_doc.append(jac)\n",
    "for doc_g,doc_o in zip(all_ents_surface_g,all_ents_surface_o):\n",
    "    jac = left_jaccard(doc_g,doc_o)\n",
    "    jaccard_ent_doc.append(jac)\n",
    "    \n",
    "jaccard_surf = left_jaccard([e for doc_g in all_surfs_surface_g for e in doc_g],[e for doc_o in all_surfs_surface_o for e in doc_o])\n",
    "jaccard_ent = left_jaccard([e for doc_g in all_ents_surface_g for e in doc_g],[e for doc_o in all_ents_surface_o for e in doc_o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4424729278884685"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_surf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39325560357824907"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48417520584959933"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(jaccard_surf_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40832415499910385"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(jaccard_ent_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
